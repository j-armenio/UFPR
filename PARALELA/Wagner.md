# Programa√ß√£o Paralela - Wagner üòí

# Processos no Unix

Programa √© passivo, c√≥digo + dados.
Processo √© um programa em execu√ß√£o, com pilha, registradores, pc, espa√ßos de mem√≥ria, heap.

### Troca de contexto 
- Trocar um processo no CPU por outro. 
- SO deve salvar e  trocar estado sem perder valores em registradores.

### Cria√ß√£o de Processos
`fork` 
- cria um novo processo igual ao processo pai, do ponto que foi chamado em diante.
- s√£o independentes, cada um com seu endere√ßo e suas c√≥pias de vari√°veis.
- retorna 0 para filho e PID do filho para o pai.

`exec` 
- substitui completamente o processo atual por outro.

`wait`
- processo espera t√©rmino dos filhos (fila de evento).

--- 

# Threads

Uma thread √© uma unidade b√°sica de utiliza√ß√£o de CPU, consiste de:
- um apontador de instru√ß√µes (PC)
- conjunto de registradores
- espa√ßo de pilha

Compartilha com outras threads pares (peers):
- se√ß√£o do c√≥digo
- se√ß√£o de dados
- recursos do SO

tudo isso coletivamente √© uma tarefa (task).

Um processo tradicional √© igual uma tarefa com uma thread.

Beneficios:
- menor tempo de resposta
- compartilhamento de recursos
- economia de recursos
- utiliza√ß√£o de arquitetura Multiprocessadores, enquanto uma thread est√° bloqueada e esperando, uma segunda na mesma tarefa pode executar

Coopera√ß√£o de m√∫ltiplas threads no mesmo job confere maior vaz√£o (*throughput*) e melhora desempenho.

**User Threads**: usadas no espa√ßo de endere√ßamento do usu√°rio, gerenciada por uma biblioteca de threads (POSIX Threads).
**Kernel Threads**: threads gerenciadas pelo SO, s√≥ o Kernel sabe que existem.

### Modelos Multithread

**Many-to-One**: Muitas threads mapeadas por uma √∫nica thread de kernel.

**One-to-One**: Cada user-level thread √© mapeada para um thread de kernel

**Many-to-Many**: Permite muitas user-level thread serem mapeadas em muitas threads de kernel.

**Two-level Model (h√≠brido)**: Similar ao M:M, exceto que permite uma thread user-level ser ligada a uma kernel thread.

### Uso pr√°tico

**Thread Pools**

- √â um n√∫mero de threads a disposi√ß√£o para executar tarefas.
- Usualmente mais r√°pido "servir" uma requisi√ß√£o √† thread pr√©-existente (cria√ß√£o e t√©rmino de thread toma tempo).

**Thread Specific Data**

- Permite cada thread a ter (alguma) √°rea de dados separada das outras.

#### Pthreads

- API padr√£o POSIX para cria√ß√£o de threads e primitivas de sincroniza√ß√£o.
- Comum em sistemas UNIX.
- Linux tem v√°rias implementa√ß√µes.

--- 

# Pthreads

Implementa o POSIX, padr√£o para criar e manipular threads.

Em `C` √© poss√≠vel utilizar a biblioteca pthread.h usando o c√≥digo:  
`#include <pthread.h>`

## Pthreads API

Subrotinas da biblioteca podem ser divididas em quatro grupos:
1. **Gerencimento de thread**: criar, remover, definir atributos e entre outros;
2. **Mutexes**: lidam com exclus√£o mutua. S√£o complementados por fun√ß√µes de atributo mutex que definem ou modificam atributos associados a mutexes;
3. **Vari√°veis de condi√ß√£o**: endere√ßam comunica√ß√µes entre threads que compartilham um mutex, baseado em condi√ß√µes especificadas pelo programador. Inclui fun√ß√µes para criar, destruir, aguardar e sinalizar com base nos valores das vari√°veis.
4. **Sincroniza√ß√£o**: Rotinas de gerenciamento de bloqueios e barreiras de leitura e escrita.

#### Compila√ß√£o

`gcc codigo.c -o codigo -lpthread`

### Gerenciamento de Thread

**Cria√ß√£o de thread**  
`pthread_create(thread, attr, start_routine, arg)`

- thread: identificador √∫nico para thread
- attr: argumento para especificar atributos (escopo, escalonamento, endere√ßo da pilha, uso da pilha, prioridade) de uma nova thread, NULL para padr√£o.
- start_routine: rotina que a thread vai executar depois de ser criada.
- arg: argumento √∫nico que pode ser passado para start_routine, se utiliza um ponteiro para struct, com todos argumentos passados por refer√™ncia e convertido em ponteiro de void.

**Finaliza√ß√£o da thread**  
Existem v√°rias formas de finalizar uma thread:
- quando ela termina a execu√ß√£o;
- quando a thread chama `pthread_exit`, retornando um status para thread pai;
- quando √© cancelado por outra thread com `pthread_cancel`.

**Join e Detaching**  
Join √© uma das maneiras de sincroniza√ß√£o entre threads. A thread que chamou `pthread_join` espera at√© que a thread especificada termine.  
`pthread_join(threadid, status)`

`pthread_detach` faz a desanexa√ß√£o de uma thread de outra.

### Mutexes

Exclus√£o m√∫tua √© uma das principais formas de se implementar sincroniza√ß√£o entre threads e proteger dados compartilhados durante a escrita, utilizados para prevenir condi√ß√µes de corrida.

**Cria√ß√£o e destrui√ß√£o de Mutexes**    
Vari√°veis mutex s√£o declaradas com o tipo `pthread_mutex_t` e devem ser inicializadas antes de serem usadas. Inicialmente s√£o desbloquedos.

`pthread_mutexattr_init()` cria atributos mutex  
`pthread_mutexattr_destroy()` destroi atributos mutex  
`pthread_mutex_destroy()` libera mutex

**Locking e Unlocking de Mutex**  
`pthread_mutex_lock()` √© usada por uma thread para dar lock em uma vari√°vel do tipo mutex.  
`pthread_mutex_trylock()` vai tentar dar lock, mas se j√° tiver om lock, ir√° retornar erro, pode previnir deadlock.  
`pthread_mutex_unlock()` vai liberar o mutex, desde que chamado pela thread que deu lock.

### Vari√°veis de condi√ß√£o

Outra forma de sincronizar threads, enquanto mutex implementa sincroniza√ß√£o com controle de acesso, vari√°veis de condi√ß√£o fazem baseado no valor atual do dado. Usa menos recursos para o mesmo objetivo.

**Criando e destruindo vari√°veis de condi√ß√£o**  
H√° duas formas de se declarar uma vari√°vel de condi√ß√£o:
- `pthread_cond_t myconvar = PTHREAD_COND_INITIALIZER` declarada de forma est√°tica.
- `pthread_cond_init()` declarada de forma din√¢mica.

`pthread_cond_destroy` libera.

### Barreiras

Quando uma thread atinge uma barreira, ela espera at√© que as outras atinja o mesmo ponto para continuar a execu√ß√£o.  
`pthread_barrier_wait()` fun√ß√£o que implementa esse comportamento.  
√â necess√°rio declarar uma vari√°vel `pthread_barrier_t` e inicializa-l√° com `pthread_barrier_init()`, que pega o n√∫mero de threads que estar√£o participando da barreira como argumento.

---

## False Sharing
Acontece quando threads diferentes escrevem em vari√°veis diferentes, mas essas vari√°veis moram na mesma linha de cache. O hardware trata como se fosse "compartilhamento verdadeiro" daquela linha, gerando um ping-pong de invalida√ß√µes e prejudicando o desempenho, mesmo sem erro l√≥gico no programa.

## Spinlocks
√â um tipo de lock baseado em *busy waiting*:
- existe uma flag at√¥mica (livre/ocupado)
- quando uma thread quer entrar na se√ß√£o cr√≠tica, ela tenta pegar o lock
    - se estiver livre -> ela entra
    - se estiver ocupada -> ela fica em loop checando a flag, at√© ficar livre

Geralmente mutex √© melhor, pois se o lock estiver ocupado, a thread s√≥ dorme e espera. Spinlocks tamb√©m s√£o mais complexos.

---

# Algoritmo Paralelo para Redu√ß√£o (Parallel Reduce)

**Defini√ß√£o**: A opera√ß√£o Redu√ß√£o (reduce) usa um operador bin√°rio qualquer, sendo esse associativo e comutativo (chamaremos de ‚äï), e aplica esse operador a um vetor de n elementos, com um valor identidade *id*: `[x_0, x_1, ..., x_n-1]`, e retorna o v√°lor √∫nico  
`(id ‚äï x_0 ‚äï x_1 ‚äï x_2 ‚äï ... ‚äï x_n-1)`.

Ou seja, **aplica o operador a todos elementos do vetor**.

*Exemplo*: Se ‚äï for adi√ß√£o, ent√£o a opera√ß√£o *reduce* no vetor `[2,3,5,1,7,6,8,4]`, com id=0, retornaria: `36`.

**Implementa√ß√£o Sequencial**  
*Exemplo*: Suponha um operador *soma* como fun√ß√£o com dois operando,

```c
resultado = id; // id=0 para soma
for (i=0; i < n; i++)
    resultado = soma(resultado, vet[i]);
```

Um algoritmo de **√°rvore de redu√ß√£o paralela** realiza N-1 opera√ß√µes em log(N) passos.

![√°rvore de redu√ßao paralela](imgs/image.png)

Para fazer em Log(N) passos precisa de N/2 processadores, mas na pr√°tica, isso nem sempre √© vi√°vel.  
Por exemplo, para implementar a redu√ß√£o paralela, podemos dividir a computa√ß√£o em t grupos de elementos e fazer uma computa√ß√£o sequencial em cada grupo dentro de cada thread. Ao final temos de fazer a redu√ß√£o de t elementos, obtendo o resultado.

--- 

# Algoritmo Paralelo para Soma de Prefixos (Prefix Sum ou Scan)

- Frequentemente usado em m√©todos paralelos de atribui√ß√£o de trabalho e aloca√ß√£o de recursos.
- Uma primitiva chave em muitos algoritmos paralelos para converter computa√ß√£o serial em paralela.

**Defini√ß√£o**: A opera√ß√£o *Scan* leva um operador associativo bin√°rio ‚äï e um vetor de n elementos `[x_0, x_1, ..., x_n]` e retorna o vetor `[x_0, (x_0 ‚äï x_1), ..., (x_0 ‚äï x_1 ‚äï ... ‚äï x_n-1)]`.

*Exemplo*: Se ‚äï for adi√ß√£o,  
no vetor: `[3, 1, 7, 0, 4, 1, 6, 3]`  
retornaria: `[3, 4, 11, 11, 15, 16, 22, 25]`.

### Aplica√ß√µes T√≠picas:

Converter recorr√™ncias de sequencial:
```c
for (j=1; j < n; j++)
    out[j] = out[j-1] + f(j);
```
Para paralelo:
```c
forall(j) {
    temp[j] = f(j); // aplica f(x) em cada posi√ß√£o em paralelo
};
scan(out, temp); // aplica o Scan
```

√ötil para algoritmos paralelos: Radix sort, Quicksort, compara√ß√£o de strings, an√°lise lexica, compara√ß√£o de fluxos(stream), avaliar polinomios, resolver recorr√™ncias, opera√ß√µes em √°rvores, histogramas, ...

---

# MPI

