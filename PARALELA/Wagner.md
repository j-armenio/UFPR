# Programa√ß√£o Paralela - Wagner üòí

# Processos no Unix

Programa √© passivo, c√≥digo + dados.
Processo √© um programa em execu√ß√£o, com pilha, registradores, pc, espa√ßos de mem√≥ria, heap.

### Troca de contexto 
- Trocar um processo no CPU por outro. 
- SO deve salvar e  trocar estado sem perder valores em registradores.

### Cria√ß√£o de Processos
`fork` 
- cria um novo processo igual ao processo pai, do ponto que foi chamado em diante.
- s√£o independentes, cada um com seu endere√ßo e suas c√≥pias de vari√°veis.
- retorna 0 para filho e PID do filho para o pai.

`exec` 
- substitui completamente o processo atual por outro.

`wait`
- processo espera t√©rmino dos filhos (fila de evento).

--- 

# Threads

Uma thread √© uma unidade b√°sica de utiliza√ß√£o de CPU, consiste de:
- um apontador de instru√ß√µes (PC)
- conjunto de registradores
- espa√ßo de pilha

Compartilha com outras threads pares (peers):
- se√ß√£o do c√≥digo
- se√ß√£o de dados
- recursos do SO

tudo isso coletivamente √© uma tarefa (task).

Um processo tradicional √© igual uma tarefa com uma thread.

Beneficios:
- menor tempo de resposta
- compartilhamento de recursos
- economia de recursos
- utiliza√ß√£o de arquitetura Multiprocessadores, enquanto uma thread est√° bloqueada e esperando, uma segunda na mesma tarefa pode executar

Coopera√ß√£o de m√∫ltiplas threads no mesmo job confere maior vaz√£o (*throughput*) e melhora desempenho.

**User Threads**: usadas no espa√ßo de endere√ßamento do usu√°rio, gerenciada por uma biblioteca de threads (POSIX Threads).
**Kernel Threads**: threads gerenciadas pelo SO, s√≥ o Kernel sabe que existem.

### Modelos Multithread

**Many-to-One**: Muitas threads mapeadas por uma √∫nica thread de kernel.

**One-to-One**: Cada user-level thread √© mapeada para um thread de kernel

**Many-to-Many**: Permite muitas user-level thread serem mapeadas em muitas threads de kernel.

**Two-level Model (h√≠brido)**: Similar ao M:M, exceto que permite uma thread user-level ser ligada a uma kernel thread.

### Uso pr√°tico

**Thread Pools**

- √â um n√∫mero de threads a disposi√ß√£o para executar tarefas.
- Usualmente mais r√°pido "servir" uma requisi√ß√£o √† thread pr√©-existente (cria√ß√£o e t√©rmino de thread toma tempo).

**Thread Specific Data**

- Permite cada thread a ter (alguma) √°rea de dados separada das outras.

#### Pthreads

- API padr√£o POSIX para cria√ß√£o de threads e primitivas de sincroniza√ß√£o.
- Comum em sistemas UNIX.
- Linux tem v√°rias implementa√ß√µes.

--- 

# Pthreads

Implementa o POSIX, padr√£o para criar e manipular threads.

Em `C` √© poss√≠vel utilizar a biblioteca pthread.h usando o c√≥digo:  
`#include <pthread.h>`

## Pthreads API

Subrotinas da biblioteca podem ser divididas em quatro grupos:
1. **Gerencimento de thread**: criar, remover, definir atributos e entre outros;
2. **Mutexes**: lidam com exclus√£o mutua. S√£o complementados por fun√ß√µes de atributo mutex que definem ou modificam atributos associados a mutexes;
3. **Vari√°veis de condi√ß√£o**: endere√ßam comunica√ß√µes entre threads que compartilham um mutex, baseado em condi√ß√µes especificadas pelo programador. Inclui fun√ß√µes para criar, destruir, aguardar e sinalizar com base nos valores das vari√°veis.
4. **Sincroniza√ß√£o**: Rotinas de gerenciamento de bloqueios e barreiras de leitura e escrita.

#### Compila√ß√£o

`gcc codigo.c -o codigo -lpthread`

### Gerenciamento de Thread

**Cria√ß√£o de thread**  
`pthread_create(thread, attr, start_routine, arg)`

- thread: identificador √∫nico para thread
- attr: argumento para especificar atributos (escopo, escalonamento, endere√ßo da pilha, uso da pilha, prioridade) de uma nova thread, NULL para padr√£o.
- start_routine: rotina que a thread vai executar depois de ser criada.
- arg: argumento √∫nico que pode ser passado para start_routine, se utiliza um ponteiro para struct, com todos argumentos passados por refer√™ncia e convertido em ponteiro de void.

**Finaliza√ß√£o da thread**  
Existem v√°rias formas de finalizar uma thread:
- quando ela termina a execu√ß√£o;
- quando a thread chama `pthread_exit`, retornando um status para thread pai;
- quando √© cancelado por outra thread com `pthread_cancel`.

**Join e Detaching**  
Join √© uma das maneiras de sincroniza√ß√£o entre threads. A thread que chamou `pthread_join` espera at√© que a thread especificada termine.  
`pthread_join(threadid, status)`

`pthread_detach` faz a desanexa√ß√£o de uma thread de outra.

### Mutexes

Exclus√£o m√∫tua √© uma das principais formas de se implementar sincroniza√ß√£o entre threads e proteger dados compartilhados durante a escrita, utilizados para prevenir condi√ß√µes de corrida.

**Cria√ß√£o e destrui√ß√£o de Mutexes**    
Vari√°veis mutex s√£o declaradas com o tipo `pthread_mutex_t` e devem ser inicializadas antes de serem usadas. Inicialmente s√£o desbloquedos.

`pthread_mutexattr_init()` cria atributos mutex  
`pthread_mutexattr_destroy()` destroi atributos mutex  
`pthread_mutex_destroy()` libera mutex

**Locking e Unlocking de Mutex**  
`pthread_mutex_lock()` √© usada por uma thread para dar lock em uma vari√°vel do tipo mutex.  
`pthread_mutex_trylock()` vai tentar dar lock, mas se j√° tiver om lock, ir√° retornar erro, pode previnir deadlock.  
`pthread_mutex_unlock()` vai liberar o mutex, desde que chamado pela thread que deu lock.

### Vari√°veis de condi√ß√£o

Outra forma de sincronizar threads, enquanto mutex implementa sincroniza√ß√£o com controle de acesso, vari√°veis de condi√ß√£o fazem baseado no valor atual do dado. Usa menos recursos para o mesmo objetivo.

**Criando e destruindo vari√°veis de condi√ß√£o**  
H√° duas formas de se declarar uma vari√°vel de condi√ß√£o:
- `pthread_cond_t myconvar = PTHREAD_COND_INITIALIZER` declarada de forma est√°tica.
- `pthread_cond_init()` declarada de forma din√¢mica.

`pthread_cond_destroy` libera.

### Barreiras

Quando uma thread atinge uma barreira, ela espera at√© que as outras atinja o mesmo ponto para continuar a execu√ß√£o.  
`pthread_barrier_wait()` fun√ß√£o que implementa esse comportamento.  
√â necess√°rio declarar uma vari√°vel `pthread_barrier_t` e inicializa-l√° com `pthread_barrier_init()`, que pega o n√∫mero de threads que estar√£o participando da barreira como argumento.

---

## False Sharing
Acontece quando threads diferentes escrevem em vari√°veis diferentes, mas essas vari√°veis moram na mesma linha de cache. O hardware trata como se fosse "compartilhamento verdadeiro" daquela linha, gerando um ping-pong de invalida√ß√µes e prejudicando o desempenho, mesmo sem erro l√≥gico no programa.

## Spinlocks
√â um tipo de lock baseado em *busy waiting*:
- existe uma flag at√¥mica (livre/ocupado)
- quando uma thread quer entrar na se√ß√£o cr√≠tica, ela tenta pegar o lock
    - se estiver livre -> ela entra
    - se estiver ocupada -> ela fica em loop checando a flag, at√© ficar livre

Geralmente mutex √© melhor, pois se o lock estiver ocupado, a thread s√≥ dorme e espera. Spinlocks tamb√©m s√£o mais complexos.

---

# Algoritmo Paralelo para Redu√ß√£o (Parallel Reduce)

**Defini√ß√£o**: A opera√ß√£o Redu√ß√£o (reduce) usa um operador bin√°rio qualquer, sendo esse associativo e comutativo (chamaremos de ‚äï), e aplica esse operador a um vetor de n elementos, com um valor identidade *id*: `[x_0, x_1, ..., x_n-1]`, e retorna o v√°lor √∫nico  
`(id ‚äï x_0 ‚äï x_1 ‚äï x_2 ‚äï ... ‚äï x_n-1)`.

Ou seja, **aplica o operador a todos elementos do vetor**.

*Exemplo*: Se ‚äï for adi√ß√£o, ent√£o a opera√ß√£o *reduce* no vetor `[2,3,5,1,7,6,8,4]`, com id=0, retornaria: `36`.

**Implementa√ß√£o Sequencial**  
*Exemplo*: Suponha um operador *soma* como fun√ß√£o com dois operando,

```c
resultado = id; // id=0 para soma
for (i=0; i < n; i++)
    resultado = soma(resultado, vet[i]);
```

Um algoritmo de **√°rvore de redu√ß√£o paralela** realiza N-1 opera√ß√µes em log(N) passos.

![√°rvore de redu√ßao paralela](imgs/image.png)

Para fazer em Log(N) passos precisa de N/2 processadores, mas na pr√°tica, isso nem sempre √© vi√°vel.  
Por exemplo, para implementar a redu√ß√£o paralela, podemos dividir a computa√ß√£o em t grupos de elementos e fazer uma computa√ß√£o sequencial em cada grupo dentro de cada thread. Ao final temos de fazer a redu√ß√£o de t elementos, obtendo o resultado.

--- 

# Algoritmo Paralelo para Soma de Prefixos (Prefix Sum ou Scan)

- Frequentemente usado em m√©todos paralelos de atribui√ß√£o de trabalho e aloca√ß√£o de recursos.
- Uma primitiva chave em muitos algoritmos paralelos para converter computa√ß√£o serial em paralela.

**Defini√ß√£o**: A opera√ß√£o *Scan* leva um operador associativo bin√°rio ‚äï e um vetor de n elementos `[x_0, x_1, ..., x_n]` e retorna o vetor `[x_0, (x_0 ‚äï x_1), ..., (x_0 ‚äï x_1 ‚äï ... ‚äï x_n-1)]`.

*Exemplo*: Se ‚äï for adi√ß√£o,  
no vetor: `[3, 1, 7, 0, 4, 1, 6, 3]`  
retornaria: `[3, 4, 11, 11, 15, 16, 22, 25]`.

### Aplica√ß√µes T√≠picas:

Converter recorr√™ncias de sequencial:
```c
for (j=1; j < n; j++)
    out[j] = out[j-1] + f(j);
```
Para paralelo:
```c
forall(j) {
    temp[j] = f(j); // aplica f(x) em cada posi√ß√£o em paralelo
};
scan(out, temp); // aplica o Scan
```

√ötil para algoritmos paralelos: Radix sort, Quicksort, compara√ß√£o de strings, an√°lise lexica, compara√ß√£o de fluxos(stream), avaliar polinomios, resolver recorr√™ncias, opera√ß√µes em √°rvores, histogramas, ...

---

# MPI (Message-Passing Interface)

Programa√ß√£o com mem√≥ria distribuida: As aplica√ß√µes s√£o vistas como um conjunto de programas executados de forma independente em diferentes processadores de diferentes computadores. 

A sincroniza√ß√£o e o funcionamento √© responsabilidade do programador.

**MPI** √© a especifica√ß√£o para programa√ß√£o paralela com mem√≥ria distribuida com diferentes implementa√ß√µes.  
`#include <mpi.h>`

**Single Program Multiple Data (SPMD)**: Modelo de programa√ß√£o onde cada processo executa uma c√≥pia de um √∫nico execut√°vel. Utilizam condi√ß√µes de teste sobre o ranking dos processos, diferentes processos executam diferentes partes.

```c
if (my_rank == 0) {
    // c√≥digo da tarefa 0
} else if (my_rank == N) {
    // c√≥digo da tarefa N
}
```

**Iniciar e Terminar ambiente de execu√ß√£o do MPI**  
`MPI_Init(int *argc, char **argv)` inicia o ambiente de execu√ß√£o MPI.  
`MPI_Finalize(void)` termina o ambiente.

- Todas fun√ß√µes MPI retornam 0 se OK, valor positivo se ERRO.

### Comunicadores
Uma aplica√ß√£o MPI v√™ seu ambiente de execu√ß√£o como um conjunto de grupos de processos. O Comunicador √© a estrutura de dados MPI que abstrai o conceito de gruo e define quais processos podem trocar mensagens.

Por padr√£o, existe o comunicador universal (`MPI_COMM_WORLD`) que engloba todos processos em execu√ß√£o. 

Todos processos possuem um identificador √∫nico (rank) que determina sua posi√ß√£o (0 a N-1) no comunicador.

`MPI_Comm_rank(MPI_Comm comm, int *rank)` devolve em rank a posi√ß√£o do processo corrente no comunicador comm.
`MPI_Comm_size()` devolve em size o total de processos do comunicador comm.

## Comunica√ß√£o

**Mensagens MPI**  
S√£o pacotes de informa√ß√£o trocados entre processos, geralmente √© designada como uma sequ√™ncia de tipo de dados.  
`MPI_CHAR, MPI_SHORT, MPI_INT, MPI_LONG, MPI_UNSIGNED_CHAR, ...`

**Envio Standard de Mensagens**  
`MPI_Send(void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)`  
Funcionalidade b√°sica para envio de mensagens.
- buf: endere√ßo inicial dos dados a enviar;
- count: n√∫mero de elementos do tipo datatype;
- datatype: tipo de dados;
- dest: posi√ß√£o do processo no comunicador comm;
- tag: marca que identifica a mensagem;
- comm: comunicador dos processos envolvidos na comunica√ß√£o;

**Recep√ß√£o Standard de Mensagens**  
`MPI_Recv(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status *status)`  
Funcionalidade b√°sica para recep√ß√£o de mensagens.
- buf: endere√ßo onde devem ser colocados os dados recebidos;
- count: n√∫mero m√°ximo de elementos datatype a receber;
- datatype: tipo de dados;
- source: posi√ß√£o do processo no comunicador comm. Pode ser `MPI_ANY_SOURCE` para receber de qualquer processo de comm.
- tag: marca que identifica mensagem. Pode ser `MPI_ANY_TAG` para receber qualquer mensagem;
- comm: comunicador envolvido com os processos;
- status: devolve informa√ß√µes sobre o processo emissor;

**Outros relativos a recep√ß√£o**  
`MPI_Get_count(MPI_Status *status, MPI_Datatype datatype, int *count)` devolve em count o n√∫mero de elementos do tipo datatype recebidos na mensagem associada com status.  
`MPI_Probe(int source, int tag, MPI_Comm comm, MPI_Status *status)` sincroniza a recep√ß√£o da pr√≥xima mensagem, retornando em status informa√ß√£o sobre a mesma contudo sem proceder sua recep√ß√£o.

*Exemplo*: I'm alive
```c
#include <mpi.h>
#define STD_TAG 0
main (int argc, char **argv) {
    int i, my_rank, n_procs; char msg[100]; MPI_Status;
    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);
    MPI_Comm_size(MPI_COMM_WORLD, &n_procs);

    if (my_rank != 0) {
        sprintf(msg, "I'm alive");
        MPI_Send(msg, strlen(msg) + 1, MPI_CHAR, 0, STD_TAG, MPI_COMM_WORLD);
    } else {
        for (i=1; i < n_procs; i++) {
            MPI_Recv(msg, 100, MPI_CHAR, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &status);
            printf("Proc %d: %s\n", status.MPI_SOURCE, msg);
        }
    }
    MPI_Finalize();
}
```

## Comunica√ß√µes Coletivas

S√£o combina√ß√µes ou varia√ß√µes de 4 opera√ß√µes primitivas: **Broadcast, Reduce, Scatter, Gather**.  
Todos os processos dever√£o chamar a mesma rotina (o processo raiz e os demais).

**Broadcast (difundir)**  
`MPI_Bcast(void *buf, int count, MPI_Datatype datatype, int root, MPI_Comm comm)`  
Faz chegar uma mensagem de um processo a todos os outros processos no comunicador.
- root: √© a posi√ß√£o do processo, em comm, que possui a mensagem a enviar.

**Reduce (reduzir)**  
`MPI_Reduce(void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype, MPI_OP op, int root, MPI_Comm comm)`   
Permite realizar opera√ß√µes globais de resumo fazneod chegar mensagens de todos os processos a um √∫nico processo no comunicador. √â quando eu tenho v√°rios subtotais e quero acumular em um lugar s√≥.
- sendv: end. inicial dos dados a enviar;
- recvbuf: end. onde devem ser colocados os dados recebidos (s√≥ importante no root);
- op: opera√ß√£o de redu√ß√£o a aplicar aos dados recebidos (`MPI_MAX, MPI_MIN, MPI_SUM, MPI_PROD, ...`);

Uma varia√ß√£o √© o `MPI_Allreduce()` onde todos recebem o resultado da redu√ß√£o.

**Scatter (espalhar)**  
`MPI_Scatter(void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm)`  
Divide em partes iguais os dados de uma mensagem e distribui ordenadamente cada uma das partes por cada um dos processos.

**Gather (reunir)**  
`MPI_Gather(void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm)`    
Recolhe ordenadamente num √∫nico processo um conjunto de mensagens oriundo de todos os processos no comunicador.

Uma varia√ß√£o √© o `MPI_Allgather()` onde todos recebem os dados de todos os processos.

**Outras varia√ß√µes**  
`MPI_SCATTERV` e `MPI_GATHERV` permitem n√∫mero vari√°vel de dados a serem enviados para cada processo.